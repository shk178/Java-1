# 11. CAS - 동기화와 원자적 연산
```
II1: result=986974, duration=[1186, 1229, 1302, 1545, 1811, 1891, 1982, 2201, 2481, 2928]
II2: result=937032, duration=[1156, 1307, 1811, 1959, 2056, 2475, 2480, 2752, 2903, 3453]
II3: result=1000000, duration=[955, 1410, 2082, 2563, 2732, 2932, 3123, 3308, 3378, 3392]
II4: result=1000000, duration=[2551, 3434, 3577, 3645, 3701, 3729, 3796, 3843, 4101, 4410]
```
- 스레드 수: 10,000개
- 각 스레드 작업: 1씩 100번 증가
- 총 기대값: 10,000 × 100 = 1,000,000
- 반복 횟수: 10번
- result: 증가된 총합 / 반복 횟수
- duration: 각 반복의 실행 시간 (ms)
- 평균 시간: II1(1,928ms), II2(2,337ms), II3(2,788ms), II4(3,729ms)
- 1. 정확성
- II1 / II2: race condition 발생. 특히 volatile은 원자성 보장 안 되므로 손실이 더 큼
- II3 / II4: 정확하게 1,000,000 → 동기화가 제대로 작동함
- 2. 성능
- II1 / II2: 락이 없어서 빠르지만, 스레드 간 충돌로 인해 캐시 무효화 + 컨텍스트 스위칭이 많아짐
- II3: synchronized는 락 오버헤드가 있지만 JVM이 잘 최적화함
- II4: AtomicInteger는 lock-free지만, 내부적으로 CAS 실패 시 재시도가 많아지면 오히려 느려질 수 있음
- 3. 왜 AtomicInteger가 가장 느렸을까
- CAS 충돌 증가: 10,000개의 스레드가 동시에 incrementAndGet()을 호출하면 CAS 실패율이 높아지고 재시도 루프가 많아짐
- 메모리 배리어 비용: AtomicInteger는 volatile 필드와 함께 메모리 배리어를 사용해 가시성과 순서를 보장 → 비용 증가
- 락 없는 구조의 역설: 락이 없다고 항상 빠른 게 아니라, 충돌이 많으면 오히려 더 느려질 수 있음
```
//스레드 작업이 1번 증가일 때 II3 / II4가 더 빨랐다.
1. CPU 캐시 일관성(Coherency) 문제
- 여러 스레드가 같은 변수에 접근하면 CPU 간 캐시 라인이 자주 무효화됨.
- 특히 int++처럼 락 없이 공유 변수에 접근하면 false sharing이 발생해 성능 저하.
- 이건 가장 큰 원인 중 하나입니다.
2. JVM의 메모리 배리어와 최적화 전략
- AtomicInteger는 내부적으로 lock-free CAS (Compare-And-Swap) 연산을 사용하며, JVM이 이를 적극적으로 최적화함.
- 반면 int++는 단순한 연산처럼 보여도, 멀티스레드 환경에서는 JIT 컴파일러가 race condition을 방지하려고 불리하게 처리할 수 있어요.
3. 컨텍스트 스위칭과 CPU 스케줄링
- 락이 없으면 스레드들이 더 자주 충돌하고, OS가 스레드를 더 자주 교체하게 됨.
- 이로 인해 컨텍스트 스위칭 비용이 증가할 수 있어요.
- AtomicInteger나 synchronized는 충돌을 줄여서 오히려 스케줄링이 더 안정적일 수 있습니다.
4. 메모리 접근 패턴의 차이
- int++는 단일 변수에 집중된 접근 → 병목 발생.
- AtomicInteger는 내부적으로 volatile 필드 + CAS → 메모리 접근이 더 분산되고 예측 가능.
5. GC(Garbage Collection) 간섭 가능성
- 실험 중 객체가 많이 생성되거나 참조가 바뀌면 GC가 개입할 수 있음.
- 특히 List<Thread>나 Runnable 객체가 반복적으로 생성되면 GC 타이밍에 따라 성능이 흔들릴 수 있어요.
```
- 강의에서
- basicInteger: CPU 캐시를 적극 활용해 빠르다. 멀티스레드에서는 사용x
- volatileInteger: 메인 메모리를 사용해 느리다. 멀티스레드에서도 사용x
- syncInteger: 멀티스레드에서 사용 가능하다.
- atomicInteger: 멀티스레드에서 사용 가능하다. 락이 없어 빠르다.
```
synchronized int++는 CPU 캐시를 활용할까? 부분적으로는 활용하지만, 제한적
- synchronized는 JVM이 락을 걸고 메모리 배리어(memory barrier)를 설정해 스레드 간 가시성과 순서를 보장합니다.
- 이때 JVM은 락을 해제할 때 변수 값을 메인 메모리에 flush하고, 다른 스레드가 락을 획득할 때 다시 메인 메모리에서 값을 읽도록 강제합니다.
- 따라서 CPU 캐시를 일시적으로 활용할 수는 있지만, 락 해제 시 반드시 메인 메모리와 동기화되므로 캐시의 이점은 제한적이에요.
AtomicInteger는 왜 메인 메모리를 쓸까? 내부적으로 volatile 필드를 사용
- AtomicInteger는 volatile int value를 기반으로 하고, incrementAndGet()은 CAS(Compare-And-Swap) 연산을 통해 원자성을 보장합니다.
- volatile은 읽기/쓰기 시 항상 메인 메모리 접근을 강제하고, CPU 캐시를 우회합니다.
- 대신 락이 없고, CAS 실패 시 재시도하는 구조라서 고충돌 환경에서는 느려질 수 있지만, 락 오버헤드가 없다는 장점이 있어요.
```

| 방식 | 캐시 활용 | 메모리 접근 | 멀티스레드 안전성 | 특징 |
|------|-----|----------------|------------|------|
| int++ | 적극 활용 | CPU 캐시 | unsafe | 빠르지만 부정확 |
| volatile int++ | 우회함 | 메인 메모리 | unsafe | 가시성만 보장 |
| synchronized int++ | 제한적 | 메인 메모리 (락 해제 시 flush) | safe | 정확하지만 느림 |
| AtomicInteger | 우회함 | 메인 메모리 (CAS 기반) | safe | lock-free, 상황에 따라 빠름 |

- CPU 캐시를 적극 활용하는 건 int++뿐이지만, 멀티스레드에서는 위험함
- synchronized는 캐시를 잠깐 활용할 수 있지만, 결국 메모리 동기화가 필수
- AtomicInteger는 캐시를 우회하고 메인 메모리 기반이지만, lock-free 구조로 성능을 확보
## CAS 연산
- CAS(Compare-And-Swap 또는 Compare-And-Set)는 원자적(atomic) 연산이다.
- 즉, 다른 스레드가 끼어들 틈 없이 한 번에 일어나는 연산
```text
/* 이걸 CPU가 하나의 원자적 명령어로 제공한다 */
if (메모리의 값 == 기대값(expected)) {
    메모리의 값을 새 값으로 바꾼다(newValue)
    return true
} else {
    아무 것도 하지 않는다
    return false
}
//Java에선 Unsafe.compareAndSwapInt()
//C/C++에선 __sync_bool_compare_and_swap()
```
왜 Compare-And-Swap / Compare-And-Set 인가
- Compare: 현재 메모리의 값이 내가 기대한 값인지 비교
- And Swap(Set): 같다면 그 자리에 새로운 값을 설정(Swap/Set)
- 즉, 비교 후 교체라서다.
왜 락-프리(lock-free)인가
- 락(lock)은 한 스레드가 락을 잡으면 다른 스레드는 기다려야 함
- 기다리는 동안 block(중단) 상태가 됨 → 문맥 전환 비용, 데드락 위험
- CAS는 락을 걸지 않고, 원자적 명령 하나로 경쟁을 해결
- 락 없이도 여러 스레드가 경쟁하면서도 안전하게 값 갱신 가능
```java
//실패하면 다시 시도(retry)한다.
do {
    oldValue = atomicValue.get();
    newValue = oldValue + 1;
} while (!atomicValue.compareAndSet(oldValue, newValue));
```
- lock-free: 어떤 스레드가 중단돼도, 시스템 전체는 계속 진행 가능
- wait-free: 각 스레드도 유한한 시간 내에 완료 보장
- CAS는 lock-free 보장은 가능하지만, wait-free는 아님
- 무한히 재시도하는 경우도 있을 수 있음
왜 락을 완전히 대체하지 못하나
- CAS가 모든 상황에서 락을 대체할 수는 없다.
- 1. 복잡한 연산에는 부적합
- CAS는 단일 값(또는 소수의 원자 필드)만 다루기 쉬움
- 여러 공유 데이터 구조를 동시에 수정해야 하면 → 락이 필요
- 2. ABA 문제
- 값이 A → B → 다시 A로 바뀌면, CAS는 변화를 감지 못함
- 이를 방지하려면 버전 번호나 스탬프를 추가해야 함 (예: AtomicStampedReference)
- 3. 재시도 비용
- 경쟁이 심할 때 계속 실패해서 busy-waiting (CPU 낭비)이 심할 수 있음
- 4. 코드 복잡도
- CAS 기반 로직은 구현이 어렵고, 디버깅 힘듦
- 반면 락 기반은 논리적으로 명확함

| 항목 | 락 (Lock) | CAS (Compare-And-Swap) |
| -- | -- | -- |
| 동작 방식 | 스레드가 자원 독점 | 원자적 비교 후 교체 |
| 블로킹 여부 | 블로킹 | 논블로킹 (락-프리) |
| 데드락 가능성 | 있음 | 없음 |
| 성능 | 경쟁 적을 땐 괜찮음 | 경쟁 적을 땐 매우 빠름 |
| 복잡한 연산 | 적합 | 어렵거나 불가능 |
| 대표적 사용 | synchronized, ReentrantLock | Atomic 변수, Concurrent 자료구조 |

기대한 값의 뜻
- 내가 마지막으로 읽은 값, 내가 알고 있는(기대하는) 메모리의 현재 상태
```java
//incrementAndGet()의 역할
//현재 값을 1 증가시키고, 증가된 값을 리턴하라는 뜻
//내부적으로는 여러 스레드가 동시에 증가시킬 수도 있으니
//CAS를 이용해 원자적으로(atomic) 증가
AtomicInteger atomicInt = new AtomicInteger(5);
int result = atomicInt.incrementAndGet();
public final int incrementAndGet() {
    int prev, next;
    do {
        prev = get(); //현재 값 읽기
        next = prev + 1; //증가시킬 값 계산
    } while (!compareAndSet(prev, next)); //CAS 실패하면 다시 시도
    return next;
}
//이 루프가 락 없이 여러 스레드의 경합을 안전하게 해결
//CAS 성공할 때까지 계속 시도 (do...while)
```
- 무한히 재시도하는 경우: 경쟁이 심할 때, 논리적 CAS 실패일 때
논리적 CAS 실패일 때
- compareAndSet() 자체는 하드웨어 명령으로 보장된 원자적 연산
```java
if (value == expected) value = newValue; //compareAndSet은 원자적 연산
//Thread A:
do {
    old = value.get(); //(1) 읽기
    newVal = old + 1; //(2) 계산
} while (!value.compareAndSet(old, newVal)); //(3) CAS 시도=계속 실패 가능
//Thread B:
while (true) {
    value.incrementAndGet(); //(1)~(3) 사이에 계속 값 변경
}
//스레드A는 전체 연산(읽기→계산→쓰기)을 하나의 원자 단위로 보장받지 못한다.
//하지만 compareAndSet()이 실패하면 상태를 되돌리고 다시 시도함으로써
//결과적으로 최종적으로는 일관된 값이 되게 한다.
//lock-free다.
//그런데 스레드B가 계속 값을 바꾸는 등 하면 계속 기다릴 수 있다.
//논리적으로 원자적이지 않은 상황이다.
//wait-free는 아니다.
//CAS 루프가 결국 성공만 한다면 논리적으로는 원자적인 연산으로 간주할 수 있다.
//물리적으로는 여러 번 시도했을 뿐, 성공한 그 한순간만 원자적이다.
//프로그램의 결과를 논리적 스냅샷으로 봤을 때, 여러 번의 실패는 시스템 상태에 영향을 주지 않는다.
//성공한 시점에만, 그 쓰기(write)는 다른 스레드에서 일관된 단일 시점의 변화로 관찰된다.
//그래서 논리적으로 원자적(atomic)이다. 실시간적 원자성(즉시성)은 없다.
//특정 스레드가 계속 실패할 수 있다. 공정성도 보장되지 않는다.
```
메인 메모리 기반의 의미
```java
//CPU가 해당 메모리 주소를 독점적으로 조작하는 동안 다른 CPU 코어가 접근하지 못하도록 보장한다.
//OS의 Mutex 락처럼 소프트웨어 락이 아니라 하드웨어 차원에서 보장하는 일시적 락이다.
//소프트웨어 락 (예: synchronized, ReentrantLock) - JVM/OS 수준에서 스레드가 블로킹
//하드웨어 락 (lock cmpxchg) - CPU 버스/캐시 라인 단위로 접근을 일시적으로 독점
//사실 CAS는 항상 메인 메모리에서 직접 수행되는 건 아니고
//CPU 캐시 계층(L1/L2/L3)에서 수행되지만
//그 캐시 라인이 다른 CPU 캐시에도 복제되어 있을 수 있기 때문에
//일관성(Coherency)을 보장하기 위해 버스 락 혹은 캐시 락이 필요하다.
//즉, CPU A와 CPU B가 같은 주소 value를 캐시에 갖고 있고
//CPU A가 lock cmpxchg 수행 시 그 캐시 라인에 대해 버스 상의 잠금 신호를 보냄
//그동안 다른 CPU는 그 캐시 라인을 읽거나 쓰지 못함
//CAS 명령이 끝나면 락이 풀리고 캐시 일관성 프로토콜(MESI 등)이 갱신된다.
//결국, 메인 메모리에 직접 락을 거는 게 아니라
//그 주소가 속한 캐시 라인을 원자적으로 조작하는 동안 다른 CPU 접근을 막는 것이다.
//CPU 내부적으로는 이렇게 동작 (하드웨어 원자성 보장)
//CPU A가 CAS 대상 메모리 주소를 L1 캐시로 로드
//lock cmpxchg 실행 → 캐시 라인 락
//레지스터의 기대값과 캐시 값 비교
//일치하면 교체, 아니면 실패
//락 해제 후 MESI 프로토콜로 다른 코어에 변경 전파한다.
//Java의 CAS가 락-프리(lock-free)인 이유
//JVM이 CAS를 요청하면 CPU의 lock cmpxchg 명령 실행
//그 명령은 아주 짧은 시간 동안만 버스 락 또는 캐시 락을 잡음
//즉, 잠깐 락이 걸리지만 OS-level 스레드 블로킹은 없음
//다른 스레드도 계속 실행되며 재시도 가능
//이걸 락-프리(lock-free)라고 부른다.
//즉, CAS는 락 없는(lock-free) 연산이지만
//하드웨어 내부에서는 락처럼 동작하는 원자적 버스 제어가 잠시 일어난다.
```
- 251011-java-adv1/src/cas/CAS.java
왜 A가 실패하다가 결국 성공하는가? 타이밍의 우연한 일치
- threadB가 incrementAndGet()을 수행하는 사이에는 값을 읽고 CAS를 시도하는 짧은 틈이 존재
- 이 짧은 틈에 threadA가 value.get()을 호출하고, 그 직후 compareAndSet()을 시도했는데,
- 그 사이에 B가 (어떤 지연으로 인해) 값을 바꾸지 않았다면, A의 CAS는 성공
- 즉, A의 CAS 성공은 B의 CAS 루프와 충돌하지 않는 순간을 포착했기 때문이다.
- compareAndSet은 낙관적 락(optimistic locking) 방식
- 실패하면 다시 시도하면 되고, 언젠가는 성공할 수 있다.
- A가 성공하는 건 B가 값을 바꾸기 직전 혹은 직후의 아주 짧은 순간을 잡았기 때문이다.
어떤 지연의 원인들
```
1. 하드웨어적인 지연
- CPU 스케줄링: OS가 스레드를 번갈아 실행시키기 때문에, B가 잠깐 멈추고 A가 실행될 수 있어요.
- 캐시 일관성(Coherency): CAS는 CPU 캐시와 메모리 간의 동기화를 필요로 하는데, 이 과정에서 미세한 지연이 생길 수 있어요.
- 멀티코어 환경: A와 B가 서로 다른 코어에서 실행되면, CAS 충돌이 발생할 확률이 높지만 동시에 충돌하지 않는 순간도 생깁니다.
2. 소프트웨어적인 지연
- GC(Garbage Collection): JVM이 GC를 수행하면 특정 스레드가 잠깐 멈출 수 있어요.
- 스레드 우선순위 및 OS 스케줄러 정책: OS가 A에게 CPU를 잠깐 더 많이 할당할 수도 있어요.
- Thread.sleep() 호출: 코드상에서 B가 1ms씩 쉬기 때문에, 그 사이에 A가 끼어들 수 있는 여지가 생깁니다.
3. JVM 내부 CAS 구현의 특성
- AtomicInteger의 compareAndSet()은 JVM 내부에서 native CAS 명령어를 사용하지만, 이 역시 루프 기반의 재시도 구조를 갖고 있어서, 충돌이 발생하면 다시 시도하게 됩니다.
- 이 재시도 루프 사이에 A가 끼어들면 성공할 수 있어요.
- 하드웨어와 소프트웨어의 복합적인 지연 요소들이 만들어낸 틈을 활용해서 경쟁을 피하고 성공하는 구조이기 때문에, 낙관적 락(optimistic locking)이라고도 불린다.
```
- 경쟁이 없다: 여러 스레드가 동시에 접근하지 않거나, 접근해도 충돌이 일어나지 않는 상태. 거의 불가능에 가까움
- 경쟁을 피한다: 경쟁이 발생할 수 있지만, 충돌을 최소화하거나 충돌 시 빠르게 복구하는 방식. CAS가 대표적
- 충돌을 무시하거나 회피하는 게 아니라, 충돌을 감지하고 효율적으로 대응한다는 뜻에 가깝다.
- 경쟁을 완전히 제거하는 게 아니라, 충돌이 생겨도 락 없이 빠르게 재시도해서 성능을 높이는 전략이다.
낙관적 락
```
- 경쟁이 자주 일어나지 않을 것이라고 낙관적으로 가정하고
- 락을 미리 걸지 않고 작업을 진행한 뒤
- 마지막에 데이터가 바뀌지 않았는지 확인해서 문제가 없으면 그대로 반영하는 방식
- 락을 미리 걸지 않음 → 성능 향상
- 작업 후 검증 → compareAndSet() 같은 CAS 연산으로 확인
- 충돌 시 재시도 → 실패하면 다시 시도하거나 롤백
- 충돌이 적은 환경에서 매우 효율적이고, 락을 걸지 않기 때문에 스레드 간 병렬성을 극대화
비관적 락(Pessimistic Locking)
- 작업 시작 전에 락을 걸고, 다른 스레드의 접근을 막음
- synchronized, ReentrantLock 등이 대표적
- 충돌이 자주 발생하는 환경에서는 안정적이지만, 성능 저하가 있을 수 있음
//낙관적 락은 충돌이 적을 것이라고 가정한다.
//앞서 스레드A, B는 충돌이 많은 것이다. 그래도 틈이 있어서 언젠가 성공한다.
//스레드A를 여러 개 만들어 동시에 실행하면 충돌이 많아지겠지만 B보다 틈이 많을 것이다.
```
- CAS 락 구현: 스핀 락을 구현할 수 있다.
- 락 해제를 반복문으로 확인하면서 기다려서 스핀 락이다.
- 임계 영역이 짧을 때 스핀 락이 좋다.
- 아니면 busy-waiting으로 CPU 자원을 많이 사용하게 된다.
- 낙관적 락, CAS의 단점도 busy-waiting이다.
- 동기화 락 (비관적 락)의 장단점
```
- 비관적 락은 충돌이 많을 것이라고 가정하고 충돌을 방지한다.
- 충돌이 발생하지 않는 장점
- 복잡한 상황에서도 일관성 있는 동작 보장한다는 장점
- 락을 대기하는 스레드가 CPU를 거의 사용하지 않는다는 장점
- 단점으로는 락 획득하는 데 대기 시간이 길어질 수 있다.
- 락 획득 대기 시점, 락 획득 시점에 스레드 상태 변경되는데 컨텍스트 스위칭 발생할 수 있다.
```
- 많은 동시성 라이브러리, 동기화 컬렉션들이 CAS 연산을 사용한다.
- 실무에서 단순 연산은 AtomicInteger 연산 같은 CAS 연산으로 구현하고
- DB나 다른 서버를 기다리는 등 대기 시간이 긴 연산은 동기화 락이나
- CAS 연산 + 상황에 최적화된 라이브러리, 컬렉션으로 구현한다.